{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP reconnaissance d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files\n",
    "import glob\n",
    "from os import mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miscellaneous\n",
    "import math\n",
    "from time import time, localtime, strftime as time_tuple_to_str, gmtime as time_float_to_tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retour sur SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va commencer avec une seule image:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptez la variable 'basedir' à votre cas\n",
    "basedir= r'''C:\\Users\\Romain\\Documents\\SSII\\TP noté images\\raw-img''' + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "  ######## ################ EXAMPLES ################ ########\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #img = io.imread(basedir+\"train/farfalla/OIP-Zq_q8o8cw50F1x6S7AmlsQHaFi.jpeg\")\n",
    "# #img = io.imread(basedir+\"train/farfalla/eb35b30729f1073ed1584d05fb1d4e9fe777ead218ac104497f5c97faeebb5bb_640.png\")\n",
    "# img = io.imread(basedir+\"train/ragno/eb3cb3082af0073ed1584d05fb1d4e9fe777ead218ac104497f5c97ca5edb3bd_640.png\")\n",
    "# plt.imshow(img)\n",
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# sift = cv2.SIFT_create()\n",
    "# now = time()\n",
    "# kp,des = sift.detectAndCompute(gray,None)\n",
    "# duration = time() - now\n",
    "# print(\"durée = %.2f s\" %duration)\n",
    "# cv2.drawKeypoints(gray,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "# plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "######## ################ EXAMPLES END ################ ########\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_SIFTs(listImages = [], n = 20, debug = True, SIFT_nbr_per_img = [], reverse = False):\n",
    "    sifts = np.empty(shape=(0, 128), dtype=int)\n",
    "    if not reverse:\n",
    "        if n > 0:\n",
    "            img_list = listImages[:int(n)]\n",
    "        elif n == -1:\n",
    "            img_list = listImages[:]\n",
    "        else:\n",
    "            img_list = listImages[:20]\n",
    "    else:\n",
    "        if n > 0:\n",
    "            img_list = listImages[-int(n):]\n",
    "        elif n == -1:\n",
    "            img_list = listImages[:]\n",
    "        else:\n",
    "            img_list = listImages[-20:]\n",
    "\n",
    "\n",
    "    for pathImg in (tqdm(img_list, position=0, leave=True) if debug else img_list):\n",
    "        img = io.imread(pathImg)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        sift = cv2.SIFT_create()\n",
    "        # kp, des = sift.detectAndCompute(gray,None)\n",
    "        des = sift.detectAndCompute(gray,None)[1]\n",
    "\n",
    "        sifts = np.append(sifts, des, axis=0)\n",
    "        \n",
    "        SIFT_nbr_per_img.append(len(des))\n",
    "\n",
    "    return sifts\n",
    "\n",
    "\n",
    "def build_BoF(img_SIFTs, km):\n",
    "    clusters_found = list(km.predict(img_SIFTs))\n",
    "    return (1/len(img_SIFTs))*np.array([clusters_found.count(i) for i in range(len(km.cluster_centers_))])\n",
    "\n",
    "\n",
    "def build_all_BoF(sifts, SIFT_nbr_per_img, km):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    previous_sift_nbr = 0\n",
    "    for sift_nbr_for_img in SIFT_nbr_per_img:\n",
    "        result.append(build_BoF(sifts[previous_sift_nbr: previous_sift_nbr + sift_nbr_for_img], km))\n",
    "        \n",
    "        previous_sift_nbr += sift_nbr_for_img\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def less_quick_build_all_BoF(classes, basedir, km, n):\n",
    "    ''' Equivalent, but much slower'''\n",
    "\n",
    "    images = [img for cl in classes for img in glob.glob(basedir + cl + '/*')[:n]]\n",
    "    \n",
    "    k = len(km.cluster_centers_)\n",
    "\n",
    "    SIFT_nbr_per_img = [] # To transform the BoF of each image from int value (count) to percentage\n",
    "\n",
    "    all_SIFTs = build_SIFTs(images, n = -1, debug = False, SIFT_nbr_per_img = SIFT_nbr_per_img)\n",
    "    \n",
    "    clusters_found = list(km.predict(all_SIFTs))\n",
    "    \n",
    "    \n",
    "    result = np.empty(shape=(0, k), dtype=float)\n",
    "    \n",
    "    previous_SIFTs_nbr = 0\n",
    "    for img_i in range(len(images)):\n",
    "        actual_SIFTs_nbr = SIFT_nbr_per_img[img_i]\n",
    "\n",
    "        this_img_BoF = np.array([clusters_found[previous_SIFTs_nbr : previous_SIFTs_nbr + actual_SIFTs_nbr].count(i)\\\n",
    "                                         for i in range(k)], dtype = float) # BoF\n",
    "        this_img_BoF /= actual_SIFTs_nbr # fraction\n",
    "\n",
    "        result = np.append(result, [this_img_BoF], axis = 0)\n",
    "        previous_SIFTs_nbr += actual_SIFTs_nbr\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_str():\n",
    "    return time_tuple_to_str('''%Y.%m.%d %Hh%Mm%Ss''', localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to save data\n",
    "\n",
    "pickle_folder = 'pickle_saves\\\\'\n",
    "pickle_extension = '.pkl'\n",
    "\n",
    "def make_pkl_dir():\n",
    "    global pickle_folder\n",
    "    try:\n",
    "        mkdir(basedir + pickle_folder)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "def save(array, name = None):\n",
    "    global basedir, pickle_folder, pickle_extension\n",
    "\n",
    "    if name == None:\n",
    "        name = time_str() + ' - array_saved' + pickle_extension\n",
    "    elif not name.endswith(pickle_extension):\n",
    "        name += pickle_extension\n",
    "    \n",
    "    make_pkl_dir()\n",
    "    \n",
    "    array.dump(basedir + pickle_folder + name)\n",
    "    return name\n",
    "\n",
    "def load(name):\n",
    "    global basedir, pickle_folder\n",
    "\n",
    "    file_name = basedir + pickle_folder + name\n",
    "    \n",
    "    make_pkl_dir()\n",
    "    try:\n",
    "        array = np.load(file_name, allow_pickle = True)\n",
    "    except:\n",
    "        print(f'Somthing went wrong while trying to retrieve data from \"{file_name}\"')\n",
    "        return np.array([])\n",
    "    else:\n",
    "        return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que contiennent les variables kp et des ? Quelles sont les dimensions ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('len(kp):', len(kp))\n",
    "#print('type(kp[0]):', type(kp[0]))\n",
    "#print()\n",
    "#print('des[0]:', des[0])\n",
    "#print('type(des[0]):', type(des[0]))\n",
    "#print('len(des[0]):', len(des[0]))\n",
    "#print()\n",
    "#print('des:', des)\n",
    "#print('type(des):', type(des))\n",
    "#print('len(des):', len(des))\n",
    "#print('des.shape:', des.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de vos classes d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseTrain = basedir + 'train/'\n",
    "baseTest = basedir + 'test/'\n",
    "classes = ['pecora','ragno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: pecora : 1456 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.98it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 12.74it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe pecora: 6.62 s\n",
      "\n",
      "class: ragno : 3856 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.63it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe ragno: 8.00 s\n",
      "\n",
      "total number of images: 5312\n",
      "longueur des SIFTs\n",
      "pecora: 36143, ragno: 31690\n",
      "{'pecora': [3409, 1212, 1940, 717, 400, 1458, 2337, 1936, 1347, 1844, 2155, 2154, 1895, 1396, 2304, 545, 1676, 1592, 2185, 3641], 'ragno': [346, 2633, 796, 1172, 172, 1032, 1932, 2583, 3405, 3147, 2200, 1010, 853, 4022, 1837, 836, 1140, 1263, 410, 901]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nb = {} # nombre d'images par classe\n",
    "SIFTs = {} # SIFTs par classe\n",
    "test_SIFTs = {}\n",
    "\n",
    "SIFT_nbr_per_img_per_cl = {}\n",
    "test_SIFT_nbr_per_img_per_cl = {}\n",
    "\n",
    "n = 20 # échantillon d'images\n",
    "\n",
    "for cl in classes:\n",
    "    SIFT_nbr_per_img_per_cl[cl] = []\n",
    "    test_SIFT_nbr_per_img_per_cl[cl] = []\n",
    "    \n",
    "    prev = time()\n",
    "    listImages = glob.glob(baseTrain + cl + '/*')\n",
    "    print('class:', cl, ':', len(listImages), 'images.') \n",
    "    nb[cl] = len(listImages)\n",
    "    SIFTs[cl] = build_SIFTs(listImages, n = n, SIFT_nbr_per_img = SIFT_nbr_per_img_per_cl[cl])\n",
    "    test_SIFTs[cl] = build_SIFTs(listImages, n = n_test, SIFT_nbr_per_img = test_SIFT_nbr_per_img_per_cl[cl], reverse = True)\n",
    "\n",
    "    print('classe {}: {:.2f} s\\n'.format(cl, time() - prev))\n",
    "\n",
    "print('total number of images:', sum(nb.values()))\n",
    "print('longueur des SIFTs')\n",
    "print(*(f'{cl}: ' + str(len(SIFTs[cl])) for cl in classes), sep = ', ')\n",
    "print(SIFT_nbr_per_img_per_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36143, 31690]\n"
     ]
    }
   ],
   "source": [
    "print([sum(i) for i in SIFT_nbr_per_img_per_cl.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in classes:\n",
    "    print(cl + ':', SIFTs[cl].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sac de descripteurs (BoF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_min = 20\n",
    "k_max = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans#, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge sifts from each class in one list\n",
    "all_SIFTs = np.empty(shape=(0, 128), dtype=int)\n",
    "all_test_SIFTs = np.empty(shape=(0, 128), dtype=int)\n",
    "\n",
    "for cl in classes:\n",
    "    all_SIFTs = np.append(all_SIFTs, SIFTs[cl], axis = 0)\n",
    "    all_test_SIFTs = np.append(all_test_SIFTs, test_SIFTs[cl], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "### Single k ###\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "\n",
    "K_Means = MiniBatchKMeans(n_clusters = k).fit(all_SIFTs)\n",
    "test_K_means = MiniBatchKMeans(n_clusters = k).fit(all_test_SIFTs)\n",
    "\n",
    "labels = K_Means.labels_ # for each SIFT, a cluster label\n",
    "\n",
    "# print({i: list(labels).count(i) for i in range(k)})\n",
    "\n",
    "\n",
    "#KMeans_dic = {} # KMeans par classe\n",
    "#labels = {} # labels par classe\n",
    "#for cl in classes:\n",
    "#    KMeans_dic[cl] = MiniBatchKMeans(n_clusters = k).fit(SIFTs[cl])\n",
    "#    labels[cl] = KMeans_dic[cl].labels_ # for each SIFT, a cluster label\n",
    "#    print(labels[cl])\n",
    "#    print({i: list(labels[cl]).count(i) for i in range(k)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67833,)\n",
      "(67833, 128)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(all_SIFTs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFTs_concat = []\n",
    "SIFTs_nbr_per_image = []\n",
    "test_SIFTs_concat = []\n",
    "test_SIFTs_nbr_per_image = []\n",
    "\n",
    "for cl in SIFTs:\n",
    "    SIFTs_concat.extend(SIFTs[cl])\n",
    "    SIFTs_nbr_per_image.extend(SIFT_nbr_per_img_per_cl[cl])\n",
    "    test_SIFTs_concat.extend(test_SIFTs[cl])\n",
    "    test_SIFTs_nbr_per_image.extend(test_SIFT_nbr_per_img_per_cl[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known lenght: 50\n",
      "[0.02112056 0.00733353 0.0164271  0.0199472  0.02757407 0.02288061\n",
      " 0.01789381 0.02053388 0.02229393 0.00792021 0.0149604  0.01408038\n",
      " 0.01056028 0.03344089 0.02229393 0.01760047 0.01056028 0.02669405\n",
      " 0.02112056 0.02552068 0.0313875  0.02112056 0.01349369 0.0214139\n",
      " 0.01818715 0.02288061 0.02258727 0.02024054 0.01701379 0.01232033\n",
      " 0.01114696 0.01906718 0.03842769 0.02552068 0.024934   0.02170725\n",
      " 0.01232033 0.01760047 0.01848049 0.01701379 0.02229393 0.02317395\n",
      " 0.02757407 0.01525374 0.0214139  0.01290701 0.01672045 0.02024054\n",
      " 0.02229393 0.03050748]\n",
      "2.483920097351074s elapsed\n"
     ]
    }
   ],
   "source": [
    "prev = time()\n",
    "\n",
    "BoFs_both_classes = build_all_BoF(SIFTs_concat, SIFTs_nbr_per_image, K_Means)\n",
    "test_BoFs_both_classes = build_all_BoF(test_SIFTs_concat, test_SIFTs_nbr_per_image, K_Means)\n",
    "\n",
    "print('known lenght:', len(BoFs_both_classes[0]))\n",
    "print(BoFs_both_classes[0])\n",
    "\n",
    "print(f'{time() - prev}s elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known lenght: 50\n",
      "[0.02170725 0.00880023 0.03461426 0.0214139  0.01114696 0.02610736\n",
      " 0.02581402 0.02669405 0.01965386 0.0313875  0.02053388 0.01730713\n",
      " 0.01877383 0.02522734 0.00968026 0.00674685 0.01936052 0.02698739\n",
      " 0.02786741 0.01818715 0.01232033 0.         0.00909358 0.02288061\n",
      " 0.02112056 0.00909358 0.01144031 0.01349369 0.02728073 0.02288061\n",
      " 0.01672045 0.02376063 0.01848049 0.02874743 0.01613376 0.02258727\n",
      " 0.02258727 0.02288061 0.02112056 0.03021414 0.0199472  0.01056028\n",
      " 0.02200059 0.02962746 0.02581402 0.03050748 0.01965386 0.01554708\n",
      " 0.01789381 0.01760047]\n",
      "10.566467046737671s elapsed\n"
     ]
    }
   ],
   "source": [
    "prev = time()\n",
    "\n",
    "BoFs_both_classes = less_quick_build_all_BoF(classes, baseTrain, K_Means, n)\n",
    "\n",
    "print('known lenght:', len(BoFs_both_classes[0]))\n",
    "print(BoFs_both_classes[0])\n",
    "\n",
    "print(f'{time() - prev}s elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Single k end #\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_Means\n",
      "25/100 in 19s\r"
     ]
    }
   ],
   "source": [
    "print('K_Means')\n",
    "K_means_dico = {}\n",
    "test_K_means_dico = {}\n",
    "\n",
    "prev = time()\n",
    "\n",
    "for k in range(k_min, k_max):\n",
    "    K_means_dico[k] = MiniBatchKMeans(n_clusters = k).fit(all_SIFTs)\n",
    "    test_K_means_dico[k] = MiniBatchKMeans(n_clusters = k).fit(all_test_SIFTs)\n",
    "    \n",
    "    print(f'{k+1}/100 in {int(time() - prev)}s', end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoFs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "build_all_BoF() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-c073e1373376>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mBoFs_both_classes_dico\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_all_BoF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_means_dico\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtest_BoFs_both_classes_dico\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_all_BoF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_K_means_dico\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: build_all_BoF() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "print('BoFs')\n",
    "BoFs_both_classes_dico = {}\n",
    "test_BoFs_both_classes_dico = {}\n",
    "\n",
    "prev = time()\n",
    "\n",
    "for k in range(k_min, k_max):\n",
    "    BoFs_both_classes_dico[k] = build_all_BoF(classes, baseTrain, K_means_dico[k], n)\n",
    "    test_BoFs_both_classes_dico[k] = build_all_BoF(classes, baseTest, test_K_means_dico[k], n)\n",
    "\n",
    "    print(f'{k+1}/100 in {int(time() - prev)}s', end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification par regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "groundTruth = [0]*n + [1]*n\n",
    "log_reg.fit(BoFs_both_classes, (groundTruth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score pour k = 50: 0.41379310344827586\n"
     ]
    }
   ],
   "source": [
    "resTrain = log_reg.predict(test_BoFs_both_classes)\n",
    "scoreTrain = f1_score((groundTruth), resTrain)\n",
    "print(f'train score pour k = {k}:', scoreTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores train\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "{20: 0.45161290322580644, 21: 0.46808510638297873, 22: 0.5555555555555556, 23: 0.6071428571428571, 24: 0.5454545454545455}\n"
     ]
    }
   ],
   "source": [
    "print('scores train')\n",
    "scoresTrain_dico = {}\n",
    "log_reg_dico = {}\n",
    "\n",
    "groundTruth = [0]*n + [1]*n\n",
    "\n",
    "for k in range(k_min, k_max):\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(BoFs_both_classes_dico[k], groundTruth)\n",
    "    print(len(BoFs_both_classes_dico[k][0]))\n",
    "\n",
    "    scoresTrain_dico[k] = f1_score(groundTruth, log_reg.predict(test_BoFs_both_classes_dico[k]))\n",
    "\n",
    "    log_reg_dico[k] = log_reg\n",
    "    \n",
    "print(scoresTrain_dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "best_k = max(scoresTrain_dico.values())\n",
    "for k in scoresTrain_dico:\n",
    "    if scoresTrain_dico[k] == best_k:\n",
    "        best_k = k\n",
    "        break\n",
    "else:\n",
    "    raise ValueError('k were not found, it is a problem')\n",
    "\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe \"pecora\"\n",
      "[array([0.38040557, 0.61959443])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features per sample; expecting 50",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-07ad61696d96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbof_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroundTruth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_reg_dico\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbof_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'class found:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python\\python 3.8.0 - 64\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python\\python 3.8.0 - 64\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    273\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features per sample; expecting 50"
     ]
    }
   ],
   "source": [
    "for cl in classes:\n",
    "    print(f'classe \"{cl}\"')\n",
    "    for img in glob.glob(baseTest + cl + '/*')[:n]:\n",
    "        \n",
    "        bof_test = build_BoF(img, K_means_dico[best_k])\n",
    "        \n",
    "        if f1_score(groundTruth, log_reg_dico[k].predict([bof_test])) >= 0.5:\n",
    "            print('class found:', cl)\n",
    "        else:\n",
    "            print('class not found (not ' + cl + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
