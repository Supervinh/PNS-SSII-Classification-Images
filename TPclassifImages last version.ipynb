{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP reconnaissance d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files\n",
    "import glob\n",
    "from os import mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miscellaneous\n",
    "import math\n",
    "from time import time, localtime, strftime as time_tuple_to_str, gmtime as time_float_to_tuple\n",
    "from tqdm import tqdm\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retour sur SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va commencer avec une seule image:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptez la variable 'basedir' à votre cas\n",
    "basedir= r'''C:\\Users\\stand\\Desktop\\Homework\\Polytech - Informatique\\Cours 2020-2021\\S6\\_8 Signals, Sounds and Images for the Informatician\\2021.04.16 - TP #10 - Catégorisations d'images\\raw-img''' + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "  ######## ################ EXAMPLES ################ ########\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #img = io.imread(basedir+\"train/farfalla/OIP-Zq_q8o8cw50F1x6S7AmlsQHaFi.jpeg\")\n",
    "# #img = io.imread(basedir+\"train/farfalla/eb35b30729f1073ed1584d05fb1d4e9fe777ead218ac104497f5c97faeebb5bb_640.png\")\n",
    "# img = io.imread(basedir+\"train/ragno/eb3cb3082af0073ed1584d05fb1d4e9fe777ead218ac104497f5c97ca5edb3bd_640.png\")\n",
    "# plt.imshow(img)\n",
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# sift = cv2.SIFT_create()\n",
    "# now = time()\n",
    "# kp,des = sift.detectAndCompute(gray,None)\n",
    "# duration = time() - now\n",
    "# print(\"durée = %.2f s\" %duration)\n",
    "# cv2.drawKeypoints(gray,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "# plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "######## ################ EXAMPLES END ################ ########\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_SIFTs(listImages = [], n = 20, debug = True, SIFT_nbr_per_img = []):\n",
    "    sifts = np.empty(shape=(0, 128), dtype=int)\n",
    "    if n > 0:\n",
    "        img_list = listImages[:int(n)]\n",
    "    elif n == -1:\n",
    "        img_list = listImages[:]\n",
    "    else:\n",
    "        img_list = listImages[:20]\n",
    "\n",
    "\n",
    "    for pathImg in (tqdm(img_list, position=0, leave=True) if debug else img_list):\n",
    "        img = io.imread(pathImg)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        sift = cv2.SIFT_create()\n",
    "        # kp, des = sift.detectAndCompute(gray,None)\n",
    "        des = sift.detectAndCompute(gray,None)[1]\n",
    "\n",
    "        sifts = np.append(sifts, des, axis=0)\n",
    "        \n",
    "        SIFT_nbr_per_img.append(len(des))\n",
    "\n",
    "    return sifts\n",
    "\n",
    "\n",
    "def build_BoF(img_SIFTs, km):\n",
    "    clusters_found = list(km.predict(img_SIFTs))\n",
    "    return (1/len(img_SIFTs))*np.array([clusters_found.count(i) for i in range(len(km.cluster_centers_))])\n",
    "\n",
    "\n",
    "def build_all_BoF(sifts, SIFT_nbr_per_img, km):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    previous_sift_nbr = 0\n",
    "    for sift_nbr_for_img in SIFT_nbr_per_img:\n",
    "        result.append(build_BoF(sifts[previous_sift_nbr: previous_sift_nbr + sift_nbr_for_img], km))\n",
    "        \n",
    "        previous += sift_nbr_for_img\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def less_quick_build_all_BoF(classes, basedir, km, n):\n",
    "    ''' Equivalent, but much slower'''\n",
    "\n",
    "    images = [img for cl in classes for img in glob.glob(basedir + cl + '/*')[:n]]\n",
    "    \n",
    "    k = len(km.cluster_centers_)\n",
    "\n",
    "    SIFT_nbr_per_img = [] # To transform the BoF of each image from int value (count) to percentage\n",
    "\n",
    "    all_SIFTs = build_SIFTs(images, n = -1, debug = False, SIFT_nbr_per_img = SIFT_nbr_per_img)\n",
    "    \n",
    "    clusters_found = list(km.predict(all_SIFTs))\n",
    "    \n",
    "    \n",
    "    result = np.empty(shape=(0, k), dtype=float)\n",
    "    \n",
    "    previous_SIFTs_nbr = 0\n",
    "    for img_i in range(len(images)):\n",
    "        actual_SIFTs_nbr = SIFT_nbr_per_img[img_i]\n",
    "\n",
    "        this_img_BoF = np.array([clusters_found[previous_SIFTs_nbr : previous_SIFTs_nbr + actual_SIFTs_nbr].count(i)\\\n",
    "                                         for i in range(k)], dtype = float) # BoF\n",
    "        this_img_BoF /= actual_SIFTs_nbr # fraction\n",
    "\n",
    "        result = np.append(result, [this_img_BoF], axis = 0)\n",
    "        previous_SIFTs_nbr += actual_SIFTs_nbr\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_str():\n",
    "    return time_tuple_to_str('''%Y.%m.%d %Hh%Mm%Ss''', localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to save data\n",
    "\n",
    "pickle_folder = 'pickle_saves\\\\'\n",
    "pickle_extension = '.pkl'\n",
    "\n",
    "def make_pkl_dir():\n",
    "    global pickle_folder\n",
    "    try:\n",
    "        mkdir(basedir + pickle_folder)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "def save(array, name = None):\n",
    "    global basedir, pickle_folder, pickle_extension\n",
    "\n",
    "    if name == None:\n",
    "        name = time_str() + ' - array_saved' + pickle_extension\n",
    "    elif not name.endswith(pickle_extension):\n",
    "        name += pickle_extension\n",
    "    \n",
    "    make_pkl_dir()\n",
    "    \n",
    "    array.dump(basedir + pickle_folder + name)\n",
    "    return name\n",
    "\n",
    "def load(name):\n",
    "    global basedir, pickle_folder\n",
    "\n",
    "    file_name = basedir + pickle_folder + name\n",
    "    \n",
    "    make_pkl_dir()\n",
    "    try:\n",
    "        array = np.load(file_name, allow_pickle = True)\n",
    "    except:\n",
    "        print(f'Somthing went wrong while trying to retrieve data from \"{file_name}\"')\n",
    "        return np.array([])\n",
    "    else:\n",
    "        return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que contiennent les variables kp et des ? Quelles sont les dimensions ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('len(kp):', len(kp))\n",
    "#print('type(kp[0]):', type(kp[0]))\n",
    "#print()\n",
    "#print('des[0]:', des[0])\n",
    "#print('type(des[0]):', type(des[0]))\n",
    "#print('len(des[0]):', len(des[0]))\n",
    "#print()\n",
    "#print('des:', des)\n",
    "#print('type(des):', type(des))\n",
    "#print('len(des):', len(des))\n",
    "#print('des.shape:', des.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de vos classes d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseTrain = basedir + 'train/'\n",
    "baseTest = basedir + 'test/'\n",
    "classes = ['pecora','ragno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: pecora : 1456 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.47it/s]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe pecora: 3.71 s\n",
      "\n",
      "class: ragno : 3856 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe ragno: 3.96 s\n",
      "\n",
      "total number of images: 5312\n",
      "longueur des SIFTs\n",
      "pecora: 36249, ragno: 31754\n",
      "{'pecora': [3448, 4638, 6607, 7333, 7736, 9165, 11526, 13416, 14764, 16620, 18788, 20927, 22824, 24266, 26570, 27107, 28792, 30396, 32608, 36249], 'ragno': [356, 2932, 3735, 4906, 5082, 6108, 8073, 10689, 14066, 17279, 19470, 20474, 21319, 25400, 27233, 28066, 29199, 30441, 30868, 31754]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nb = {} # nombre d'images par classe\n",
    "SIFTs = {} # SIFTs par classe\n",
    "\n",
    "SIFT_nbr_per_img_per_cl = {}\n",
    "\n",
    "n = 20 # échantillon d'images\n",
    "\n",
    "for cl in classes:\n",
    "    SIFT_nbr_per_img_per_cl[cl] = []\n",
    "    \n",
    "    prev = time()\n",
    "    listImages = glob.glob(baseTrain + cl + '/*')\n",
    "    print('class:', cl, ':', len(listImages), 'images.') \n",
    "    nb[cl] = len(listImages)\n",
    "    SIFTs[cl] = build_SIFTs(listImages, n = n, SIFT_nbr_per_img = SIFT_nbr_per_img_per_cl[cl])\n",
    "\n",
    "    print('classe {}: {:.2f} s\\n'.format(cl, time() - prev))\n",
    "\n",
    "print('total number of images:', sum(nb.values()))\n",
    "print('longueur des SIFTs')\n",
    "print(*(f'{cl}: ' + str(len(SIFTs[cl])) for cl in classes), sep = ', ')\n",
    "print(SIFT_nbr_per_img_per_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pecora: (36249, 128)\n",
      "ragno: (31754, 128)\n"
     ]
    }
   ],
   "source": [
    "for cl in classes:\n",
    "    print(cl + ':', SIFTs[cl].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sac de descripteurs (BoF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_min = 2\n",
    "k_max = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans#, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge sifts from each class in one list\n",
    "all_SIFTs = np.empty(shape=(0, 128), dtype=int)\n",
    "for cl in classes:\n",
    "    all_SIFTs = np.append(all_SIFTs, SIFTs[cl], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "### Single k ###\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "\n",
    "K_Means = MiniBatchKMeans(n_clusters = k).fit(all_SIFTs)\n",
    "labels = K_Means.labels_ # for each SIFT, a cluster label\n",
    "\n",
    "# print({i: list(labels).count(i) for i in range(k)})\n",
    "\n",
    "\n",
    "#KMeans_dic = {} # KMeans par classe\n",
    "#labels = {} # labels par classe\n",
    "#for cl in classes:\n",
    "#    KMeans_dic[cl] = MiniBatchKMeans(n_clusters = k).fit(SIFTs[cl])\n",
    "#    labels[cl] = KMeans_dic[cl].labels_ # for each SIFT, a cluster label\n",
    "#    print(labels[cl])\n",
    "#    print({i: list(labels[cl]).count(i) for i in range(k)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known lenght: 50\n",
      "[0.03422274 0.02639211 0.01769142 0.01421114 0.01450116 0.02552204\n",
      " 0.03016241 0.02523202 0.00435035 0.01363109 0.01682135 0.02349188\n",
      " 0.02668213 0.01508121 0.02813225 0.02204176 0.02552204 0.00696056\n",
      " 0.02204176 0.01479118 0.02175174 0.01972158 0.02175174 0.02204176\n",
      " 0.01508121 0.01740139 0.01740139 0.01653132 0.02204176 0.02668213\n",
      " 0.02233179 0.02407193 0.01595128 0.01653132 0.02204176 0.02146172\n",
      " 0.01885151 0.01537123 0.02697216 0.01450116 0.03364269 0.01537123\n",
      " 0.01682135 0.02581206 0.01537123 0.02059165 0.02059165 0.01769142\n",
      " 0.01740139 0.01073086]\n",
      "13.841761589050293s elapsed\n"
     ]
    }
   ],
   "source": [
    "prev = time()\n",
    "\n",
    "BoFs_both_classes = build_all_BoF(classes, baseTrain, K_Means, n)\n",
    "\n",
    "print('known lenght:', len(BoFs_both_classes[0]))\n",
    "print(BoFs_both_classes[0])\n",
    "\n",
    "print(f'{time() - prev}s elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known lenght: 50\n",
      "[0.03422274 0.02639211 0.01769142 0.01421114 0.01450116 0.02552204\n",
      " 0.03016241 0.02523202 0.00435035 0.01363109 0.01682135 0.02349188\n",
      " 0.02668213 0.01508121 0.02813225 0.02204176 0.02552204 0.00696056\n",
      " 0.02204176 0.01479118 0.02175174 0.01972158 0.02175174 0.02204176\n",
      " 0.01508121 0.01740139 0.01740139 0.01653132 0.02204176 0.02668213\n",
      " 0.02233179 0.02407193 0.01595128 0.01653132 0.02204176 0.02146172\n",
      " 0.01885151 0.01537123 0.02697216 0.01450116 0.03364269 0.01537123\n",
      " 0.01682135 0.02581206 0.01537123 0.02059165 0.02059165 0.01769142\n",
      " 0.01740139 0.01073086]\n",
      "16.21074151992798s elapsed\n"
     ]
    }
   ],
   "source": [
    "prev = time()\n",
    "\n",
    "BoFs_both_classes = less_quick_build_all_BoF(classes, baseTrain, K_Means, n)\n",
    "\n",
    "print('known lenght:', len(BoFs_both_classes[0]))\n",
    "print(BoFs_both_classes[0])\n",
    "\n",
    "print(f'{time() - prev}s elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Single k end #\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#### Many k ####\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_Means\n"
     ]
    }
   ],
   "source": [
    "print('K_Means')\n",
    "K_means_dico = {}\n",
    "\n",
    "prev = time()\n",
    "\n",
    "for k in range(k_min, k_max):\n",
    "    K_means_dico[k] = MiniBatchKMeans(n_clusters = k).fit(all_SIFTs)\n",
    "    \n",
    "    print(f'{k+1}/100 in {int(time() - prev)}s', end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoFs\n",
      "100/100 in 885s\r"
     ]
    }
   ],
   "source": [
    "print('BoFs')\n",
    "BoFs_both_classes_dico = {}\n",
    "\n",
    "prev = time()\n",
    "\n",
    "for k in range(k_min, k_max):\n",
    "    BoFs_both_classes_dico[k] = build_all_BoF(classes, baseTrain, K_means_dico[k], n)\n",
    "\n",
    "    print(f'{k+1}/100 in {int(time() - prev)}s', end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification par regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log_reg = LogisticRegression()\n",
    "\n",
    "#groundTruth = [0]*n + [1]*n\n",
    "#log_reg.fit(sample_BoFs_both_classes, groundTruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score pour k = 50: 0.6\n"
     ]
    }
   ],
   "source": [
    "#resTrain = log_reg.predict(sample_BoFs_both_classes)\n",
    "#scoreTrain = f1_score(groundTruth, resTrain)\n",
    "#print(f'train score pour k = {k}:', scoreTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores train\n",
      "{2: 0.6, 3: 0.6, 4: 0.6, 5: 0.6, 6: 0.6, 7: 0.6, 8: 0.6, 9: 0.6, 10: 0.6, 11: 0.6, 12: 0.6, 13: 0.6, 14: 0.6, 15: 0.6, 16: 0.6, 17: 0.6, 18: 0.6, 19: 0.6, 20: 0.6, 21: 0.6, 22: 0.6, 23: 0.6, 24: 0.6, 25: 0.6, 26: 0.6, 27: 0.6, 28: 0.6, 29: 0.6, 30: 0.6, 31: 0.6, 32: 0.6, 33: 0.6, 34: 0.6, 35: 0.6, 36: 0.6, 37: 0.6, 38: 0.6, 39: 0.6, 40: 0.6, 41: 0.6, 42: 0.6, 43: 0.6, 44: 0.6, 45: 0.6, 46: 0.6, 47: 0.6, 48: 0.6, 49: 0.6}\n"
     ]
    }
   ],
   "source": [
    "print('scores train')\n",
    "scoresTrain_dico = {}\n",
    "log_reg_dico = {}\n",
    "\n",
    "groundTruth = [0]*n + [1]*n\n",
    "\n",
    "for k in range(k_min, k_max):\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(BoFs_both_classes_dico[k], list(groundTruth))\n",
    "\n",
    "    scoresTrain_dico[k] = f1_score(list(groundTruth), log_reg.predict(BoFs_both_classes_dico[k]))\n",
    "\n",
    "    log_reg_dico[k] = log_reg\n",
    "    \n",
    "print(scoresTrain_dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "best_k = max(scoresTrain_dico.values())\n",
    "for k in scoresTrain_dico:\n",
    "    if scoresTrain_dico[k] == best_k:\n",
    "        best_k = k\n",
    "        break\n",
    "else:\n",
    "    raise ValueError('k were not found, it is a problem')\n",
    "\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe \"pecora\"\n",
      "[array([0.38040557, 0.61959443])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features per sample; expecting 50",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-07ad61696d96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbof_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroundTruth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_reg_dico\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbof_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'class found:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python\\python 3.8.0 - 64\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python\\python 3.8.0 - 64\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    273\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features per sample; expecting 50"
     ]
    }
   ],
   "source": [
    "for cl in classes:\n",
    "    print(f'test images from class \"{cl}\"')\n",
    "    for img in glob.glob(baseTest + cl + '/*')[:n]:\n",
    "        \n",
    "        bof_test = build_BoF(img, K_means_dico[best_k])\n",
    "        \n",
    "        if f1_score(groundTruth, log_reg_dico[k].predict([bof_test])) >= 0.5:\n",
    "            print('class found:', cl)\n",
    "        else:\n",
    "            print(f'class not found (not {cl})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
